{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "An NOAA dataset has been stored in the file `data/C2A2_data/BinnedCsvs_d400/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv`. This is the dataset to use for this assignment. Note: The data for this assignment comes from a subset of The National Centers for Environmental Information (NCEI) [Daily Global Historical Climatology Network](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt) (GHCN-Daily). The GHCN-Daily is comprised of daily climate records from thousands of land surface stations across the globe.\n",
    "\n",
    "Each row in the assignment datafile corresponds to a single observation.\n",
    "\n",
    "The following variables are provided to you:\n",
    "\n",
    "* **id** : station identification code\n",
    "* **date** : date in YYYY-MM-DD format (e.g. 2012-01-24 = January 24, 2012)\n",
    "* **element** : indicator of element type\n",
    "    * TMAX : Maximum temperature (tenths of degrees C)\n",
    "    * TMIN : Minimum temperature (tenths of degrees C)\n",
    "* **value** : data value for element (tenths of degrees C)\n",
    "\n",
    "For this assignment, you must:\n",
    "\n",
    "1. Read the documentation and familiarize yourself with the dataset, then write some python code which returns a line graph of the record high and record low temperatures by day of the year over the period 2005-2014. The area between the record high and record low temperatures for each day should be shaded.\n",
    "2. Overlay a scatter of the 2015 data for any points (highs and lows) for which the ten year record (2005-2014) record high or record low was broken in 2015.\n",
    "3. Watch out for leap days (i.e. February 29th), it is reasonable to remove these points from the dataset for the purpose of this visualization.\n",
    "4. Make the visual nice! Leverage principles from the first module in this course when developing your solution. Consider issues such as legends, labels, and chart junk.\n",
    "\n",
    "The data you have been given is near **Ann Arbor, Michigan, United States**, and the stations the data comes from are shown on the map below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet\n",
    "import pandas as pd\n",
    "\n",
    "def leaflet_plot_stations(binsize, hashid):\n",
    "\n",
    "    df = pd.read_csv('data/C2A2_data/BinSize_d{}.csv'.format(binsize))\n",
    "\n",
    "    station_locations_by_hash = df[df['hash'] == hashid]\n",
    "\n",
    "    lons = station_locations_by_hash['LONGITUDE'].tolist()\n",
    "    lats = station_locations_by_hash['LATITUDE'].tolist()\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    plt.scatter(lons, lats, c='r', alpha=0.7, s=200)\n",
    "\n",
    "    return mplleaflet.display()\n",
    "\n",
    "leaflet_plot_stations(400,'fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "binsize = 'fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89'\n",
    "df = pd.read_csv('data/C2A2_data/BinnedCsvs_d400/{}.csv'.format(binsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2025 records are lone pairs = each day only has either min or max:\n",
    "\n",
    "## Create a dataframe where per ID, Date there is only 1 rec\n",
    "size = df.groupby(['ID', 'Date']).size()\n",
    "size1 = size[size==1]\n",
    "dt = pd.DataFrame(size1, columns={'size'}).reset_index()\n",
    "dt.shape\n",
    "dt.head()\n",
    "\n",
    "## Now zip ID, Date into paired values in a list\n",
    "size1list =  list(zip(dt['ID'], dt['Date']))\n",
    "\n",
    "## Method1: Use named function\n",
    "def matching(x):\n",
    "    return x in size1list\n",
    "#df1 = df[list(map(matching, list(zip(df['ID'], df['Date']))))]\n",
    "\n",
    "## Method2: Use unnamed lambda function\n",
    "df1 = df[list(map(lambda x: x in size1list, list(zip(df['ID'], df['Date']))))]\n",
    "\n",
    "df1.shape\n",
    "df1.sort_values(['ID', 'Date']).head()\n",
    "\n",
    "## Method3 (preferred)\n",
    "#df2=df[df.apply(lambda row: (row['ID'], row['Date']) in size1list, axis=1)]\n",
    "#df2.equals(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 10\n",
    "## Method2: Use unnamed lambda function\n",
    "#df1 = df[list(map(lambda x: x in size1list, list(zip(df['ID'], df['Date']))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 10\n",
    "## Method3: pass each row values as tuple\n",
    "#df2=df[df.apply(lambda row: (row['ID'], row['Date']) in size1list, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of stations\n",
    "df['ID'].nunique()\n",
    "df[['ID']].groupby('ID').size()\n",
    "\n",
    "#Date Range\n",
    "# dt[['Date']].groupby('Date').size()\n",
    "dt1 = df.copy()\n",
    "dt1 = dt1.set_index('Date')\n",
    "dt1.index = pd.to_datetime(dt1.index).to_period('M')\n",
    "month = pd.DataFrame(dt1.groupby(dt1.index).size(), columns={'size'})\n",
    "month.index[0]; month.index[-1]\n",
    "%matplotlib inline\n",
    "#month.plot(figsize=(12,6))\n",
    "\n",
    "#fig = plt.figure(figsize=(10,6))\n",
    "##fig, ax = plt.subplots(fig, ax = plt.subplots())\n",
    "#plt.plot(month.index.to_timestamp(), month['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enough playing around. Now work on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset to just 2005 -2014\n",
    "binsize = 'fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89'\n",
    "df = pd.read_csv('data/C2A2_data/BinnedCsvs_d400/{}.csv'.format(binsize))\n",
    "df = df.set_index('Date')\n",
    "df.head()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df14 = df['2005':'2014'].sort_index()\n",
    "print('Data now subset to date between {} - {}'.format(df14.index[0], df14.index[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get max of TMAX and min of TMIN regardless of station ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now get max of TMAX and min of TMIN regardless of station ID\n",
    "import numpy as np\n",
    "table = df14.pivot_table(index=df14.index.date, columns='Element', values='Data_Value', aggfunc=[np.max, np.min])\n",
    "# table.head()\n",
    "# table.columns\n",
    "table = table.loc[: ,[('amax','TMAX'), ('amin','TMIN')]]\n",
    "table.columns = table.columns.droplevel()\n",
    "table.head().append(table.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify min and max temp\n",
    "mx = df14[df14['Element']=='TMAX'].groupby(df14[df14['Element']=='TMAX'].index.date)['Data_Value'].agg({'TMAX':max}).head()\n",
    "mn = df14[df14['Element']=='TMIN'].groupby(df14[df14['Element']=='TMIN'].index.date)['Data_Value'].agg({'TMIN':min}).head()\n",
    "all(mx.assign(TMIN=mn)==table.head())\n",
    "\n",
    "mx = df14[df14['Element']=='TMAX'].groupby(df14[df14['Element']=='TMAX'].index.date)['Data_Value'].agg({'TMAX':max}).tail()\n",
    "mn = df14[df14['Element']=='TMIN'].groupby(df14[df14['Element']=='TMIN'].index.date)['Data_Value'].agg({'TMIN':min}).tail()\n",
    "all(mx.assign(TMIN=mn)==table.tail())\n",
    "\n",
    "#Pick one day to look at\n",
    "df.loc['2005-01-04'][df.loc['2005-01-04'].apply(lambda row: row['Element']=='TMAX', axis=1)].sort_values('Data_Value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get min and max temp per day across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First format index to mm-dd\n",
    "table.index = pd.to_datetime(table.index).strftime('%m-%d')\n",
    "table.head().append(table.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check mm-dd index\n",
    "len(list(table.index))\n",
    "# set(table.index)\n",
    "\n",
    "#Check volume per mm-dd -- expect n=10\n",
    "t = pd.DataFrame(table.groupby(table.index).size(), columns={'size'})\n",
    "t[t['size']!=10]\n",
    "\n",
    "#Remove index=02-29, n=2\n",
    "table=table.drop('02-29')\n",
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate temp values\n",
    "table.sort_index().head(20)\n",
    "table.sort_index().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = table.groupby(level=0).agg({'TMAX':np.max, 'TMIN': np.min})\n",
    "table1.head().append(table1.tail())\n",
    "len(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now reset index to full calendar dates to make plotting easier\n",
    "#Make sure to pick a year that is not a leap year\n",
    "table1.index=pd.date_range('2014-01-01', periods=365)\n",
    "# table1.index[0]; table1.index[-1]\n",
    "table1.head(); table1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "tmax = plt.plot(table1.index, table1['TMAX'])\n",
    "tmin = plt.plot(table1.index, table1['TMIN'])\n",
    "\n",
    "#table1.plot(figsize=(10,6))    \n",
    "\n",
    "#fill the area between the linear data and exponential data\n",
    "plt.gca().fill_between(table1.index, \n",
    "                       table1['TMIN'], table1['TMAX'], \n",
    "                       facecolor='blue', \n",
    "                       alpha=0.25)                         \n",
    "plt.xlabel('Date')\n",
    "plt.title('Temperature Range (tenths of degrees C) in Ann Arbor, Michigan over 2005 - 2014')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show 1st and 15th of the month in xticks\n",
    "x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "# for item in x.get_ticklabels():\n",
    "#     item.set_rotation(45)\n",
    "    \n",
    "import matplotlib.dates as mdates\n",
    "maj_locator = mdates.DayLocator(bymonthday=1, interval=1, tz=None)\n",
    "min_locator = mdates.DayLocator(bymonthday=15, interval=1, tz=None)\n",
    "x.set_major_locator(maj_locator)\n",
    "x.set_minor_locator(min_locator)\n",
    "\n",
    "maj_formatter= mdates.DateFormatter('%b')\n",
    "min_formatter= mdates.DateFormatter('%d')\n",
    "x.set_major_formatter(maj_formatter)\n",
    "# x.set_minor_formatter(min_formatter)  #Comment out to show just tick mark without value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set xlim to elimiate side space\n",
    "left, right = plt.xlim() \n",
    "print(mdates.num2date(left), mdates.num2date(right))\n",
    "\n",
    "plt.xlim(table1.index.date[0], table1.index.date[-1])\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now get 2015 data\n",
    "df15 = df['2015'].sort_index()\n",
    "print('Data now subset to date between {} - {}'.format(df15.index[0], df15.index[-1]))\n",
    "# len(df14) + len(df15) == len(df)\n",
    "\n",
    "#Check last day in Feb = 28\n",
    "print('Last day in 2015 Feb = ', df15['2015-02'].index[-1].day)\n",
    "df15.head()\n",
    "table2 = df15.pivot_table(index=df15.index.date, columns='Element', values='Data_Value', aggfunc=[np.max, np.min])\n",
    "                          \n",
    "table2.head()\n",
    "table2.columns\n",
    "table2 = table2.loc[: ,[('amax','TMAX'), ('amin','TMIN')]]\n",
    "table2.columns = table2.columns.droplevel()\n",
    "table2.head().append(table2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset date index to 2014 calendar dates to be consistent with table1 for plotting on the same axis\n",
    "table2.set_index(table1.index, inplace=True)\n",
    "table2.head().append(table2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask 2015 temperatures that didn't break 2005 - 2014 record high and low\n",
    "table2['TMAX1'] = list(map(lambda x, y: x if x > y else np.nan, table2['TMAX'], table1['TMAX']))\n",
    "table2['TMIN1'] = list(map(lambda x, y: x if x < y else np.nan, table2['TMIN'], table1['TMIN']))\n",
    "\n",
    "#Check 2015 data against table1\n",
    "table2.head()\n",
    "table2[np.isnan(table2['TMAX1'])==False].head()\n",
    "idx = table2[np.isnan(table2['TMAX1'])==False].head().index\n",
    "table1.loc[idx]\n",
    "\n",
    "table2[np.isnan(table2['TMIN1'])==False].head()\n",
    "idx = table2[np.isnan(table2['TMIN1'])==False].head().index\n",
    "table1.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now scatter-plot 2015 highs and lows\n",
    "scat_max=plt.scatter(x=table2.index, y=table2['TMAX1'], c='cyan')\n",
    "scat_min=plt.scatter(x=table2.index, y=table2['TMIN1'], c='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scat_max.remove()\n",
    "# scat_min.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add caption\n",
    "## Remove any existing figure text first\n",
    "for txt in fig.texts:\n",
    "    txt.set_visible(False)\n",
    "txt =fig.text(0.1, 0.03, 'Minor x-tickmarks indicates the 15th of the month', horizontalalignment='left')\n",
    "txt1 =fig.text(0.1, 0.01, 'Overlay scatter plot of 2015 highs and lows that broke the 10-year records', horizontalalignment='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "print(*zip(handles, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add legend\n",
    "plt.legend(handles=handles, labels = ['TMAX', 'TMIN', '2015 TMAX', '2015 TMIN'], loc = 'upper center'\n",
    "           , bbox_to_anchor = (0.5,-0.15), ncol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
